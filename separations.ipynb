{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Exploring Separations factors in CPS ASEC data\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    html-math-method: katex\n",
        "    css: styles.css\n",
        "---"
      ],
      "id": "27ddca17"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting ASEC data from CPS API\n"
      ],
      "id": "cebb2b1f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathlib as pl\n",
        "import os\n",
        "import requests\n",
        "\n",
        "ASEC_VARIABLES = [\n",
        "    'PEMLR', # labor force status\n",
        "    'WKSWORK', # weeks worked last year\n",
        "    'A_AGE',\n",
        "    'A_SEX',\n",
        "    'A_HGA',\n",
        "    'PRDTRACE',\n",
        "    'PEHSPNON',\n",
        "    'PRDISFLG',\n",
        "    'PRCITSHP',\n",
        "    'MARSUPWT',\n",
        "    'A_LFSR',\n",
        "    'HRCHECK',\n",
        "    'A_CLSWKR',\n",
        "    'CLWK',\n",
        "    'A_DTOCC', # last year major occ\n",
        "    'WEMIND', # last year major ind\n",
        "    'A_MJIND',\n",
        "    'LJCW',\n",
        "    'HTOTVAL',\n",
        "    'A_MARITL',\n",
        "    'FPERSONS',  # number of persons in family\n",
        "    'FRELU18',  # number of persons in family under 18\n",
        "]\n",
        "\n",
        "# this function will retrieve an entire year of ASEC data\n",
        "def get_asec_year_df(api_key, asec_variables, year):\n",
        "    base_url = f'https://api.census.gov/data/{year}/cps/asec/mar'\n",
        "    get_vars = ','.join(asec_variables)\n",
        "    url = f'{base_url}?get={get_vars}&key={api_key}'\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    data = response.json()\n",
        "    df = pd.DataFrame(data[1:], columns=data[0])\n",
        "    \n",
        "    df = df.rename(columns={x: x.lower() for x in df.columns})\n",
        "    df.loc[:, 'year'] = year\n",
        "    \n",
        "    for var in df.columns:\n",
        "        if var == 'marsupwt':\n",
        "            df[var] = df[var].astype(np.float64)\n",
        "        else:\n",
        "            df[var] = df[var].astype(np.int64)\n",
        "            \n",
        "    return df\n",
        "\n",
        "# I've saved my API key in a local file\n",
        "with open('c:/users/calvi/coding/census_api_key.txt', 'r') as f:\n",
        "    api_key = f.readline().strip()\n",
        "\n",
        "asec = pd.DataFrame()\n",
        "base_year = 2024\n",
        "start_year = base_year - 9\n",
        "for year in range(start_year, base_year + 1):\n",
        "    print(f'Processing year {year}')\n",
        "    df_year = get_asec_year_df(api_key, ASEC_VARIABLES, year)\n",
        "    asec = pd.concat([\n",
        "        asec,\n",
        "        df_year\n",
        "    ])\n",
        "\n",
        "asec.head()"
      ],
      "id": "2d12505e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform data to prepare for modeling\n",
        "\n",
        "### Get price data from BLS\n",
        "\n",
        "We need to account for inflation to make incomes comparable across years.\n"
      ],
      "id": "1098d8fb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "\n",
        "BLS_CPI_SERIES = 'CUUR0000SA0'  # CPI-U\n",
        "\n",
        "# Get CPI data from BLS API \n",
        "headers = {'Content-type': 'application/json'}\n",
        "data = json.dumps({\"seriesid\": [BLS_CPI_SERIES],\n",
        "                   \"startyear\": str(start_year - 1), \n",
        "                   \"endyear\": str(base_year-  1)})\n",
        "p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', \n",
        "                  data=data, headers=headers)\n",
        "json_data = json.loads(p.text)\n",
        "\n",
        "# put CPI data into dataframe and calculate inflation rates\n",
        "cpi = pd.DataFrame(json_data['Results']['series'][0]['data'])\n",
        "cpi = cpi[cpi.period == 'M12']  # only keep end of year numbers\n",
        "cpi = cpi[['year', 'value']]\n",
        "cpi.year = cpi.year.astype(np.int64)\n",
        "cpi.value = cpi.value.astype(np.float64)\n",
        "cpi = cpi.sort_values('year', ascending=False).reset_index(drop=True)\n",
        "cpi['inflation'] = cpi.value / cpi.value.shift(-1) - 1\n",
        "cpi"
      ],
      "id": "5210dc3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inflation numbers look accurate. Let's Cacluate price level ratios indexed to 2023 prices now. The years will be shifted by one, because incomes in each year of ASEC data correspond to the previous year's income:\n"
      ],
      "id": "53937e4a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cpi_2023 = cpi[cpi.year == 2023].value.iloc[0]\n",
        "cpi['pl_ratio'] = cpi_2023 / cpi.value\n",
        "cpi['year'] = cpi['year'] + 1\n",
        "cpi"
      ],
      "id": "688b814f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean ASEC data\n"
      ],
      "id": "1bf7d311"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def remove_rows(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # only include people who worked in paying jobs last year\n",
        "    df = df[df.ljcw.isin([1,2,3,4,5,6])].reset_index(drop=True)\n",
        "\n",
        "    # only include people who worked more than 30 weeks\n",
        "    df = df[df.wkswork > 30]\n",
        "\n",
        "    return df\n",
        "\n",
        "def get_edu_var(df):\n",
        "    df = df.copy()\n",
        "    bins = [30, 39, 40, 41, 43, 44, 45, np.inf]\n",
        "    names = ['LTHS', 'HS', 'SCND', 'AD', 'BA', 'MA', 'DOC']\n",
        "    df['edu'] = pd.cut(df['a_hga'], bins, labels=names, right=False)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_race_var(df):\n",
        "    df = df.copy()\n",
        "    df['race'] = 'other'\n",
        "    df.loc[df.prdtrace == 1, 'race'] = 'white'\n",
        "    df.loc[df.prdtrace == 2, 'race'] = 'black'\n",
        "    df.loc[df.prdtrace == 4, 'race'] = 'asian'\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_hispanic_var(df):\n",
        "    df = df.copy()\n",
        "    df['hisp'] = 0\n",
        "    df.loc[df.pehspnon==1, 'hisp'] = 1\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_male_var(df):\n",
        "    df = df.copy()\n",
        "    df['male'] = 0\n",
        "    df.loc[df.a_sex==1, 'male'] = 1\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_citizenship_var(df):\n",
        "    df = df.copy()\n",
        "    bins = [1, 4, 5, np.inf]\n",
        "    names = ['native', 'naturalized', 'noncitizen']\n",
        "    df.loc[:, 'citshp'] = pd.cut(df['prcitshp'],\n",
        "                                 bins=bins, labels=names, right=False, include_lowest=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_cow_var(df):\n",
        "    df = df.copy()\n",
        "    bins = [1, 2, 5, 6, np.inf]\n",
        "    names = ['ws', 'gov', 'seinc', 'seuninc']\n",
        "    df.loc[:, 'cow'] = pd.cut(df['ljcw'],\n",
        "                                 bins=bins, labels=names, \n",
        "                                 right=False, include_lowest=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_pt_var(df):\n",
        "    df = df.copy()\n",
        "    df['pt'] = 0\n",
        "    df.loc[df.hrcheck == 1, 'pt'] = 1\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_disability_var(df):\n",
        "    df = df.copy()\n",
        "    df['disability'] = 0\n",
        "    df.loc[df.prdisflg == 1, 'disability'] = 1\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_married_var(df):\n",
        "    df = df.copy()\n",
        "    df['married'] = 0\n",
        "    df.loc[df.a_maritl.isin([1,2,3]), 'married'] = 1\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_children_var(df):\n",
        "    df = df.copy()\n",
        "    df['children'] = 0\n",
        "    df.loc[df.frelu18 > 0, 'children'] = 1\n",
        "    \n",
        "    return df\n",
        "\n",
        "def get_log_income_var(df, cpi):\n",
        "    df = df.copy()\n",
        "    cpi = cpi.copy()\n",
        "    \n",
        "    # adjust incomes to price level\n",
        "    df = df.merge(cpi[['year', 'pl_ratio']], on='year')\n",
        "    df['income_adjusted'] = df.htotval * df.pl_ratio\n",
        "    \n",
        "    # initially set to 0\n",
        "    df['log_income'] = 0.0\n",
        "    # only assign log value to positive values - we will treat negative and 0 income as all having 0 here\n",
        "    df.loc[df.income_adjusted > 0, 'log_income'] = \\\n",
        "        np.log(df[df.income_adjusted > 0].income_adjusted)\n",
        "        \n",
        "    # remove cpi column\n",
        "    df = df.drop('pl_ratio', axis=1)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# This is the label for classification\n",
        "def get_leaver_var(df):\n",
        "    df = df.copy()\n",
        "    df['leaver'] = 0\n",
        "    df.loc[~df.pemlr.isin([1,2]), 'leaver'] = 1\n",
        "    \n",
        "    return df\n",
        "\n",
        "asec = remove_rows(asec)\n",
        "asec = get_edu_var(asec)\n",
        "asec = get_race_var(asec)\n",
        "asec = get_hispanic_var(asec)\n",
        "asec = get_male_var(asec)\n",
        "asec = get_citizenship_var(asec)\n",
        "asec = get_cow_var(asec)\n",
        "asec = get_pt_var(asec)\n",
        "asec = get_disability_var(asec)\n",
        "asec = get_married_var(asec)\n",
        "asec = get_children_var(asec)\n",
        "asec = get_log_income_var(asec, cpi)\n",
        "asec = get_leaver_var(asec)\n",
        "\n",
        "print('Percentage workers who are classified as leavers', \n",
        "      str(round(asec.leaver.sum()/len(asec), 4)*100) + '%')"
      ],
      "id": "7561a03d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just over 5% of workers in our dataset are classified as \"Labor force leavers\"\n",
        "\n",
        "### Final steps for preparing model data\n"
      ],
      "id": "3998b0aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "asec = asec.rename(columns={\n",
        "    'a_dtocc': 'occ',\n",
        "    'wemind': 'ind',\n",
        "    'a_age': 'age'\n",
        "})\n",
        "\n",
        "model_data = asec[[\n",
        "    'marsupwt', 'leaver',  # weight and label\n",
        "    'age', 'log_income',  # continuous variables\n",
        "    'pt', 'hisp', 'male', 'disability', 'married', 'children',  # binary variables\n",
        "    'cow', 'race', 'citshp', 'edu', 'occ', 'ind' # categorical variables\n",
        "]].copy()\n",
        "\n",
        "cat_vars = ['cow', 'race', 'citshp', 'edu', 'occ', 'ind']\n",
        "\n",
        "for var in cat_vars:\n",
        "    model_data[var] = model_data[var].astype('category')\n",
        "\n",
        "# one-hot encode categorical variables\n",
        "model_data = pd.get_dummies(model_data, drop_first=True,\n",
        "                            columns=cat_vars, dtype=np.int8)"
      ],
      "id": "0ca2012e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models\n",
        "\n",
        "### Split data into training and test sets\n"
      ],
      "id": "fd758fe7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# I'll use a smaller sample of the data to speed up processing times\n",
        "sample = model_data.sample(200000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# scale age and income variables\n",
        "continuous_features = ['age', 'log_income']\n",
        "scaler = StandardScaler()\n",
        "sample[continuous_features] = scaler.fit_transform(sample[continuous_features])\n",
        "\n",
        "X = sample.drop(columns=['leaver', 'marsupwt'])\n",
        "y = sample['leaver']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print('training size:', len(X_train))\n",
        "print('test size:', len(X_test))"
      ],
      "id": "970ff2de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PCA\n",
        "\n",
        "Let's see if we can identify any patterns with Principal component Analysis.\n"
      ],
      "id": "ccb92697"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Run PCA, reducing the data to 2 components\n",
        "pca = PCA()\n",
        "pca.fit(X_train)\n",
        "\n",
        "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "# Plot the first two principal components\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, len(explained_variance) + 1),\n",
        "        explained_variance, marker='o', linestyle='--')\n",
        "plt.xlabel(\"Number of principale components\")\n",
        "plt.ylabel(\"cumulative explained variance\")\n",
        "plt.title(\"Explained variance by principal components\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "6f082bd9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are the variables assigned which explain the most variance in our PCA model. Perhaps unsurprisingly, the continuous variables (age and income) are the most explanatory:\n"
      ],
      "id": "41ecd41e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Rank the importance of variables\n",
        "importance_rank = np.argsort(explained_variance_ratio)[::-1]\n",
        "\n",
        "# Print the ranked variables\n",
        "pca_importance = []\n",
        "for i, var_index in enumerate(importance_rank[:10]):\n",
        "    pca_importance.append(X.columns[var_index])\n",
        "    print(f\"Rank {i+1}: Variable {X.columns[var_index]}\")"
      ],
      "id": "058d0d30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest\n",
        "\n",
        "Let's implement a random forest model to gather more insights about our data.\n",
        "\n",
        "Note that our data is imbalanced. We should use balanced class weights to mitigate this:\n"
      ],
      "id": "42f55605"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "leavers_frac = y.sum()/len(y)\n",
        "leavers_frac_pct = round(leavers_frac*100, 1)\n",
        "\n",
        "print(f\"{leavers_frac_pct}% of the rows in our sample have a leaver value of 1\")"
      ],
      "id": "7cccec0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100,\n",
        "                            class_weight='balanced',\n",
        "                            random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "a6c795bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even when using the balanced class weights, our model predicts a low amount of leavers:\n"
      ],
      "id": "d86b0120"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pred_leavers_frac = y_pred.sum()/len(y_pred)\n",
        "pred_leavers_frac_pct = round(pred_leavers_frac*100, 1)\n",
        "\n",
        "print(f\"{pred_leavers_frac_pct}% of training data was predicted to be leavers by the model\")"
      ],
      "id": "018f6e0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's make a confusion matrix and compute some metrics:"
      ],
      "id": "54c98961"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('F1:', f1_score(y_test, y_pred))"
      ],
      "id": "eb85ee01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Precision is quite high, meaning that the vast majority of positive predictions were correct. Recall was just over 50%, which means the model was only able to identify classify a little over half of the leavers. Given the imbalance in the data, this isn't terrible\n",
        "\n",
        "Let's see which features this random forest assessed as most important. Just like we saw in PCA, income and age are the most important features, but this time income is ranked higher than age. Unlike what we saw in PCA, an industry and 5 occupations were among the most important features in this model.\n"
      ],
      "id": "27a02582"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(pd.Series(rf.feature_importances_, index=X.columns) \\\n",
        "    .sort_values(ascending=False)[:10])"
      ],
      "id": "846d4809",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start adding these importance rankings to a DataFrame we can use to compare the rankings from different models:\n"
      ],
      "id": "2d5c47ab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "importance_rankings = pd.DataFrame({\n",
        "    'Rank': list(range(1,11)),\n",
        "    'PCA': pca_importance,\n",
        "    'Random Forest': list(\n",
        "        pd.Series(rf.feature_importances_, index=X.columns) \\\n",
        "        .sort_values(ascending=False)[:10].index),\n",
        "})\n",
        "importance_rankings"
      ],
      "id": "9d7649fd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}